{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: MinHash and finding similar items\n",
    "\n",
    "## Part 1: Jaccard Similarity and Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this piece of code is here to help wiht development using python module `plagiarism_lib`\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plagiarism_lib` module includes a function to shingle documents. Here is an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nt', 'at', 'th', 'ti', 'eh', 'ha', 'in', 'he', 'ca', 'ec'}\n"
     ]
    }
   ],
   "source": [
    "import plagiarism_lib.article_db as art_db\n",
    "\n",
    "shingles = art_db._shingle_text('The cat in the hat', 2)\n",
    "print(shingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to answer the following questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4782608695652174"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 1: What is the jaccard similarity of these two sentences using 2-shingles:\n",
    "s1 = \"I would drink black tea\"\n",
    "s2 = \"I would drink green tea\"\n",
    "\n",
    "sh1 = art_db._shingle_text(s1, 2)\n",
    "sh2 = art_db._shingle_text(s2, 2)\n",
    "\n",
    "len(sh1.intersection(sh2)) / len(sh1.union(sh2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question 2: What is the jaccard similarity of these two sentences using 2-shingles:\n",
    "s1 = \"I would drink green tea but I would not drink black tea\"\n",
    "s2 = \"I would not drink green tea but I would drink black tea\"\n",
    "\n",
    "sh1 = art_db._shingle_text(s1, 2)\n",
    "sh2 = art_db._shingle_text(s2, 2)\n",
    "\n",
    "len(sh1.intersection(sh2)) / len(sh1.union(sh2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3, what is the smallest shingle length we need to use \n",
    "# to distinguish these two sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data\n",
    "\n",
    "Run the following piece of code to fetch data to use in the project, and to setup experiment code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plagiarism_lib.fetch_data as fetch\n",
    "import plagiarism_lib.jaccard_experiment as jaccard_exp\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch small dataset from data repository\n",
    "DATA_PATH = 'data'\n",
    "\n",
    "fetch.fetch_data(path=DATA_PATH, maxsize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data'\n",
    "train_file = DATA_PATH + '/articles_1000.train'\n",
    "truth_file = DATA_PATH + '/articles_1000.truth'\n",
    "\n",
    "import os\n",
    "\n",
    "RESDIR_PATH = 'result_data'\n",
    "if not os.path.isdir(RESDIR_PATH):\n",
    "    os.mkdir(RESDIR_PATH)\n",
    "    \n",
    "jaccard_exp_csv = RESDIR_PATH + '/jaccard_exp_res.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity\n",
    "\n",
    "**TODO** Finish implementing the function `plagiarism_lib.jaccard._jaccard_similarity` to compute the Jaccard Similarity of two sets.\n",
    "\n",
    "Once you do that run the next chunk to perform an experiment on the effect of shard-length $k$ on Jaccard similarity of\n",
    "plagiarism instances versus instances that are not plagiarized.\n",
    "\n",
    "Make sure you set `RUN_JACCARD_EXP = True` to get your experiment data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if needed\n",
    "RUN_JACCARD_EXP = False\n",
    "if RUN_JACCARD_EXP:\n",
    "    exp_res = jaccard_exp.run(train_file, truth_file)\n",
    "    exp_res.to_csv(jaccard_exp_csv, index=False)\n",
    "else:\n",
    "    exp_res = pd.read_csv(jaccard_exp_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code makes a plot with $k$ in the x-axis and average Jaccard similarity in the y-axis with two lines:\n",
    "one for plagiarism instances, one for instances that are not plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# start here just to make plot\n",
    "plot_df = exp_res.melt(id_vars=['k'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = []\n",
    "\n",
    "for key, grp in plot_df.groupby('variable'):\n",
    "    ax = grp.plot(ax=ax, kind='line', x='k', y='value')\n",
    "    labels.append(key)\n",
    "lines, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Comment on what you observe from this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: MinHash and Jaccard Similarity\n",
    "\n",
    "Load article data, preprocess it and shingle articles with length $k=10$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plagiarism_lib.article_db import ArticleDB\n",
    "\n",
    "artdb = ArticleDB(train_file)\n",
    "exp_data = artdb.shingle_data(k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Jaccard similarities for pairs of articles in corpus. Set `RUN_MAKE_JS_DF=True` to prepare data on Jaccard similarity for our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plagiarism_lib.minhash_experiment as minhash_exp\n",
    "import pandas as pd\n",
    "\n",
    "js_csv_file = RESDIR_PATH + '/js_df.csv'\n",
    "\n",
    "# Switch True/False to run as needed\n",
    "RUN_MAKE_JS_DF = False\n",
    "\n",
    "if RUN_MAKE_JS_DF:\n",
    "    exp_df = minhash_exp.make_js_df(exp_data, artdb._docids)\n",
    "    exp_df.to_csv(js_csv_file, index=False)\n",
    "else:\n",
    "    exp_df = pd.read_csv(js_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Finish implementing function `plagiarism_lib.minhash._make_minhash_sigmatrix` to construct the minhash signature matrix of the document collection.\n",
    "\n",
    "**TODO**: Finish implementing function `plagiarism_lib.minhash.MinHash.get_similarity` to compute the minhash estimate of Jaccard similarity given two minhash signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed the above todos, let's compute minhash similarity matrices with varying number of hash functions and compute Jaccard similarity estimates. Set `RUN_MAKE_MH_DF=True` and run the following chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_csv_file = RESDIR_PATH + '/mh_df.csv'\n",
    "\n",
    "hash_vals = [10, 20, 50, 100, 1000]\n",
    "RUN_MAKE_MH_DF = False\n",
    "if RUN_MAKE_MH_DF:\n",
    "    minhash_exp.run(exp_data, exp_df, hash_vals=hash_vals)\n",
    "    exp_df.to_csv(mh_csv_file, index=False)\n",
    "else:\n",
    "    exp_df = pd.read_csv(mh_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk computes the error of minhash similarity estimates. We are going to use that to see what the effect of the number of hashes used in the minhash signature affects the error of the MinHash estimate of Jaccard similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df = minhash_exp.post_process_df(exp_df, hash_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk plots root mean squared error between minhash JS estimate and exact Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "rmse_df.plot(x='h',y='rmse')#, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Comment on the effect of the number of hashes used in the minhash signature matrix and the error of the MinHash estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: LSH\n",
    "\n",
    "Prepare article database for training file, using $k=10$ for shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plagiarism_lib.lsh_experiment as lsh_exp\n",
    "from plagiarism_lib.article_db import ArticleDB\n",
    "from plagiarism_lib.minhash import invert_shingles, MinHash\n",
    "from pathlib import Path\n",
    "\n",
    "numdocs = 1000\n",
    "trainfile = DATA_PATH + '/articles_%d.train' % numdocs\n",
    "\n",
    "k = 10\n",
    "print(\"Preparing Data\")\n",
    "artdb = ArticleDB(trainfile)\n",
    "inv_data, docids = invert_shingles(artdb.shingle_data(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the minhash signature matrix with 100 rows (hash functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hash = 100\n",
    "mh_mat_file = RESDIR_PATH + '/mh_mat_%d_%d_%d.npy' % (numdocs, k, num_hash)\n",
    "\n",
    "mh = MinHash(num_hash)\n",
    "if Path(mh_mat_file).is_file():\n",
    "    print(\"Loading MH signature matrix from file\")\n",
    "    mh.from_file(docids, mh_mat_file)\n",
    "else:\n",
    "    print(\"Creating minhash matrix with %d hashes\" % num_hash)\n",
    "    mh.make_matrix((inv_data, docids), inverted=True) \n",
    "    mh.save_matrix(mh_mat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Finish implementing function `plagiarism_lib.lsh._do_lsh` to implement Locality Sensitive Hashing.\n",
    "\n",
    "Once that is done, run an experiment of using LSH with desired similarity threshold values to detect plagiarism. Set `RUN_LSH_EXP=True` and run the following chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plagiarism_lib.lsh_experiment as lsh_exp\n",
    "\n",
    "DEFAULT_TS = [.01, .05, .10, .30, .50, .70, .90, .95, .99]\n",
    "\n",
    "truthfile = DATA_PATH + '/articles_%d.truth' % numdocs\n",
    "\n",
    "\n",
    "RUN_LSH_EXP = False\n",
    "if RUN_LSH_EXP:  \n",
    "    exp_df = lsh_exp.run(mh, truthfile, ts=DEFAULT_TS)\n",
    "    exp_df.to_csv(csv_file, index=False)\n",
    "else:\n",
    "    exp_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk plots precision and recall of this system as a function of the LSH threshold chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plot_df = exp_df.melt(id_vars=['t'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "labels = []\n",
    "\n",
    "for key, grp in plot_df.groupby('variable'):\n",
    "    ax = grp.plot(ax=ax, kind='line', x='t', y='value')\n",
    "    labels.append(key)\n",
    "lines, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(lines, labels, loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Comment on the behavior of precision and recall as a function of similarity threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
